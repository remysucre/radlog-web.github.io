<html>

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>RaDlog</title>
  <meta name="viewport" content="width=device-width">

  <!-- syntax highlighting CSS -->
  <link href="css/prism.css" type="text/css" rel="stylesheet" />

  <!-- Custom CSS -->
  <link rel="stylesheet" type="text/css" href="//netdna.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
  <link rel="stylesheet" type="text/css" href="css/main.css">

  <!--<link rel="shortcut icon" href="#">-->
</head>

<body>
<!-- Fixed navbar -->
<div class="navbar navbar-default navbar-static-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <!--a class="navbar-brand" href="#">
        <img src="" alt="" class="logo">
      </a-->
    </div>
    <div class="navbar-collapse collapse">
      <ul class="nav navbar-nav">

        <!--li>
          <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Papers &amp; Projects <span class="caret"></span></a>
          <ul class="dropdown-menu" role="menu">
            <li><a href="#">Projects</a></li>
            <li><a href="#">Publications</a></li>
            <li><a href="#">Source Code</a></li>
          </ul>
        </li-->

        <li>
          <a href="#" onclick="show('intro_body');">RaDlog</a>
        </li>

        <li>
          <a href="#" onclick="show('lang_body');">Language</a>
        </li>

        <li>
          <a href="#" onclick="show('example_body');">Examples</a>
        </li>

        <li>
          <a href="#" onclick="show('pub_body');">Publications</a>
        </li>

        <li>
          <a href="#" onclick="show('tutorial_body');">Tutorial</a>
        </li>

        <!--li>
          <a href="#">GitHub</a>
        </li-->

        <!--li class="active dropdown">
          <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Documentation <span class="caret"></span></a>
          <ul class="dropdown-menu" role="menu">

          <li class="dropdown-header">DOC1</li>
              <li><a href="#">1.1</a></li>
              <li><a href="#">1.2</a></li>

          <li class="dropdown-header">DOC2</li>
              <li><a href="#">2.1</a></li>
              <li><a href="#">2.2</a></li>

          <li class="dropdown-header">DOC3</li>
              <li><a href="#">2.1</a></li>
              <li><a href="#">3.2</a></li>
          </ul>
        </li-->

      </ul>
    </div><!--/.nav-collapse -->
  </div>
</div>

<div id="intro_body" class="container">
  <h1>RaDlog</h1>
  <p> RaDlog is a powerful and scalable delcarative data analytics system, leveraging Datalog semantics to deliver an integrated system that covers a wide spectrum of applications, ranging from graph analysis to knowledge discovery.
  <h2 class="cc">1. Knowledge Discovery</h2>
  <p> RaDlog is equipped with a scalable and declarative framework, to enable efficient knowledge discovery and data mining, and cover a broad range of applications. In RaDlog, KDD models are expressed by recursive queries with traditional aggregates, enriched with the new notion of chain aggregates. The efficient execution of these programs exploits the extended <strong>PreM</strong> property which enables a highly optimized fixpoint computation for aggregates. Thus, RaDlogâ€™s main steps taken to realizes the various KDD models are as follows: 1) KDD models are first compiled into a Predicate Connection Graph (PCG) to identify the exit rules and recursive rules, then 2) PCG is mapped into a tree of relational and fixpoint operators, i.e. the corresponding logical plan, and finally 3) the logical plan is transformed into physical plan with corresponding physical operators and scheduled for execution according to the optimized semi-naive fixpoint semantics.<br />

  <p> We implement this framework on top of Apache Spark, extending the Datalog engine provided by BigDatalog for query compilation and execution scheduling on Spark. The RaDlog system is fully integrated with the Apache Spark system via the extensible KDDLib library designed to assist everyday users to construct knowledge discovery tasks, along with a simple interface to add newly developed models to KDDLib. With KDDLib, the efforts required to introduce new models or extending existing ones can be significantly reduced by the use of recursive queries with aggregates.
  <br />

  <h2 class="cc">2. RaSQL</h2>
  <p>RaSQL language is an extension of the current SQL standard by allowing the use of the
    aggregates such as <code class="highlighter-rouge">min</code>, <code class="highlighter-rouge">max</code>, <code class="highlighter-rouge">count</code> and <code class="highlighter-rouge">sum</code> in the <i>Common Table Expression</i> (<strong>CTE</strong>) by which recursive queries can be expressed in the current standard.
    The exclusion of aggregates from the Recursive CTE of current standards was largely due to concerns about semantics and implementation caused by the non-monotonic nature of aggregates, since this can compromise the least-fixpoint semantics of these queries.
    Therefore, the current SQL standard merely supports queries that are stratified w.r.t. aggregates, i.e., the recursive queries (with no aggregates) produce their results first and only after that the aggregates can be applied.</p>

  <p>Fortunately, it was recently shown that recursive queries with aggregates that satisfy a <i>Pre-Mappability</i> <strong>PreM</strong> condition produce the same results as the stratified program; thus they are semantically equivalent but evaluate much more efficiently than their stratified counterparts - and actually they are safe
    in many situations when the stratified queries are not.
    Moreover, by using <code class="highlighter-rouge">min</code>, <code class="highlighter-rouge">max</code>, <code class="highlighter-rouge">count</code> and <code class="highlighter-rouge">sum</code> in programs that satisfy PreM, we can write queries that express most polynomial-time algorithms of frequent usage.</p>

  <!--h2 id="syntax-and-semantics">2. Language Syntax and Semantics</h2-->

<h2 class="cc">3. BigDatalog</h2>
  <p> BigDatalog is a full Datalog language implementation on Apache Spark developed under the Deductive Application Language System (<strong>DeALS</strong>) project at UCLA. The DeALS project seeks to (1) design a unified logical language that enables the concise and declarative expression of analytics, and (2) provide a system that optimizes execution over diverse platforms including sequential implementations, multi-core machines, and clusters (with BigDatalog).<br />

  <p>BigDatalog supports relational algebra, aggregation, and recursion, as well as a host of declarative optimizations. It also exploits semantic exten- sions for programs with aggregation in recursion. As a result, the Spark programmer can now implement complex analytics pipelines of relational, graph and machine learning tasks in a single language, instead of stitching together programs written in different APIs, i.e., Spark SQL, GraphX and MLlib.
  <br />
</div>

<div id="lang_body" class="container">
  <!-- <h1>RaSQL (Recursive-aggregate-SQL)</h1> -->
  <h2 class="cc">1. Datalog</h2>

  <p> A Datalog program is defined by a set rules with the form: <code class="highlighter-rouge">h &#8592; b<sub>1</sub>, &hellip; ,b<sub>n</sub></code>, where <code class="highlighter-rouge">h</code> and <code class="highlighter-rouge">b<sub>1</sub>, &hellip; ,b<sub>n</sub></code> are respectively called the head and body of this rule, and each <code class="highlighter-rouge">b<sub>i</sub></code> are its atoms. The rule head <code class="highlighter-rouge">h</code> and each <code class="highlighter-rouge">b<sub>i</sub></code> are atoms, with the form <code class="highlighter-rouge">p<sub>i</sub>(t<sub>1</sub>, &hellip; , t<sub>j</sub>)</code> where <code class="highlighter-rouge">p<sub>i</sub></code> is a predicate and <code class="highlighter-rouge">t<sub>1</sub>, &hellip; , t<sub>j</sub></code> are terms which can be constants or variables. The comma separating each <code class="highlighter-rouge">b<sub>i</sub></code> in the body denotes the logical conjunction (AND). On occasions, we use the terms predicate, table and relation interchangeably. In a Datalog program, predicates can be either the base relations stored in extensional database (EDB), or the derived relations defined by rules heads of the rules, forming the intensional database (IDB). As a convention, predicate names and constant begin with lower case letters, and variable names begin with upper case letters.


<p> To illustrate the syntax and semantics of Datalog with aggregates, consider a simplified Bill of Materials(<strong>BOM</strong>) example where we have two EDB relations: <code class="highlighter-rouge">assbl</code> and <code class="highlighter-rouge">basic</code>. The <code class="highlighter-rouge">assbl</code> table describes the assembling relationships between a <code class="highlighter-rouge">Part</code> and associated sub-parts. Not all items are assembled: basic parts are purchased directly from external suppliers and will be delivered in a certain number of days, which is described in the <code class="highlighter-rouge">basic</code> table. <code class="highlighter-rouge">ddays</code> is an derived relation, indicating the number of days required for the item to be ready. We have simple assemblies, such as bikes, where a bike and its sub-parts are assembled as soon as all its basic sub-parts arrive. Thus, the number of required days is the maximum day when all sub-parts are delivered, as illustrated
by following query. This query recursively produces pairs of <code class="highlighter-rouge">Part</code>and the maximum number of <code class="highlighter-rouge">Days</code> required for assembly.

<pre>
  <code class="language-sql">Relations: assbl(Part, Sub), basic(Part, Days).
  r<sub>1</sub>:ddays(Part, Days) &#8592; basic(Part, Days).
  r<sub>2</sub>:ddays(Part, Days) &#8592; assbl(Part, Sub), ddays(Sub, Days).
  r<sub>3</sub>: mxdays(Part, max&lt;Days&gt;) &#8592; ddays(Part, Days).
  query  mxdays(Part, MxDays).</code>
</pre>
<br/>
<p> Rule <code class="highlighter-rouge">r<sub>2</sub></code> is recognized as recursive since the predicate <code class="highlighter-rouge">ddays</code> appears in both the head and body. The recursive IDB relation <code class="highlighter-rouge">ddays</code> is also the head for non-recursive rule <code class="highlighter-rouge">r<sub>1</sub></code>, which is a <code class="highlighter-rouge">base rule</code> because it serves as a base case of the recursion. Since at most one recursive goal is included in the body of any rule, this query represents a case of <code class="highlighter-rouge">linear recursion</code>; the term <code class="highlighter-rouge">linear recursion</code> denotes instead the case where some rules contain multiple recursive goals. In rule <code class="highlighter-rouge">r<sub>3</sub></code>, <code class="highlighter-rouge">max<Days></code> specifies the application of the <code class="highlighter-rouge">max</code> aggregate upon <code class="highlighter-rouge">Days</code>, with the remaining head attributes, i.e., <code class="highlighter-rouge">Part</code> in our example,  implicitly defined as the group-by attributes.

<h2 class="cc">2. RaSQL</h2>
  <p>We use the classical <strong>BOM</strong> example, an important recursive query application in <strong>SQL:99</strong>, to illustrate the syntax and semantics of RaSQL and the PreM property.

  <p>In SQL:99, the BOM query can be expressed as follows:


  <pre><code class="language-sql">/*Q1: Days Till Delivery by a Stratified Program*/
WITH recursive waitfor(Part, Days) AS     
  (SELECT Part, Days FROM basic)
    UNION 
  (SELECT assbl.Part, waitfor.Days
  FROM assbl, waitfor
  WHERE assbl.Spart = waitfor.Part)
SELECT Part, max(Days) FROM waitfor GROUP BY Part
</code></pre></p>


  <p>RaSQL still supports this query, but also supports an equivalent and much more efficient version as below.


  <pre><code class="language-sql">/*Q2: The Equivalent Endo-Max Program*/
WITH recursive waitfor(Part, max() as Days) AS
   (SELECT Part, Days FROM basic)
      UNION 
   (SELECT assbl.Part, waitfor.Days
    FROM assbl, waitfor
    WHERE assbl.Spart = waitfor.Part)
SELECT Part, Days FROM waitfor
</code></pre></p>


  <p>Note that from a syntax point of view, RaSQL query only makes a small change to replace the <strong>stratified max</strong> (stratified aggregate means it can only be applied to the result of recursive evaluation, not within the recursive evaluation process) used in <code class="highlighter-rouge">Q1</code> by the <code class="highlighter-rouge">max</code> aggregate in the recursive CTE head of <code class="highlighter-rouge">Q2</code>.
    However, it is non-trivial to show that <code class="highlighter-rouge">Q1</code> and <code class="highlighter-rouge">Q2</code> are equivalent semantically and evaluate to the same result, which is discussed below. </p>

  The semantics for query <code class="highlighter-rouge">Q1</code> and <code class="highlighter-rouge">Q2</code> are defined by <i>naive fixpoint evaluation</i> shown in Algorithm 1 and 2,  where the following abbreviations are used: </p>

  <code class="highlighter-rouge">wf = waitfor</code><br/>
  <code class="highlighter-rouge">&#8904; = &#8904; <sub>(assbl.Spart=wf.Part)</sub></code><br/>
  <code class="highlighter-rouge">&#120587; = &#120587; <sub>(assbl.Part=wf.Days)</sub></code><br/>
  <code class="highlighter-rouge">max = <sub>Part</sub> max <sub>Days</sub></code><br/>

  <img src="algorithms.png" alt="Algorithms" class="responsive">

  <p>We denote the <i>Relational Algebra</i> <strong>(RA)</strong> expression used in line 5 of Algorithm 1 as <code class="highlighter-rouge">T</code>, which derives the new <code class="highlighter-rouge">wf'</code> from the old <code class="highlighter-rouge">wf</code>. The operators used by <code class="highlighter-rouge">T</code> are <i>union</i>, <i>join</i> and <i>project</i>, which are monotonic and guarantees that when <code class="highlighter-rouge">wf'=wf</code>, we obtain the <strong>least fixpoint</strong> solution of equation <code class="highlighter-rouge">wf=T(wf)</code>, which defines the formal semantics of the Recursive CTE <code class="highlighter-rouge">Q1</code>.
    The last line in <code class="highlighter-rouge">Q1</code> contains a non-monotonic <code class="highlighter-rouge">max</code> aggregate which is applied to <code class="highlighter-rouge">wf</code> when the fixpoint <code class="highlighter-rouge">wf=T(wf)</code> is reached. This computation is performed at  line 7 of Algorithm 1, which computes the perfect-model for query <code class="highlighter-rouge">Q1</code> that is stratified w.r.t. <code class="highlighter-rouge">max</code>.</p>

  <p>Algorithm 2 shows the naive-fixpoint evaluation for <code class="highlighter-rouge">Q2</code>. The <code class="highlighter-rouge">max</code> aggregate has been moved from the final statement in <code class="highlighter-rouge">Q1</code> to the head of the Recursive CTE in <code class="highlighter-rouge">Q2</code>.
    Thus the <code class="highlighter-rouge">max</code>aggregate which was in line 7 of Algorithm 1 has now been moved  to line 1 and 5 of Algorithm 2 - i.e., lines that specify the initial and iterative computation of <code class="highlighter-rouge">wf</code>.</p>

  <p>This example illustrates that supporting aggregates in the <i>WITH recursive</i> clause requires only simple extensions at the syntax level, and techniques such as semi-naive fixpoint and magic sets also require simple extensions when aggregates are allowed in recursion. However aggregates in recursion raise major semantics issues caused by their non-monotonic nature.
    Fortunately the recent introduction of the PreM property has enabled much progress on this problem. In fact, the PreM holds for this example which indicates <code class="highlighter-rouge">Q1</code> and <code class="highlighter-rouge">Q2</code> will produce the same results (concrete semantics) and <code class="highlighter-rouge">Q2</code> has a minimal fixpoint semantics that is equivalent to the perfect model semantics of <code class="highlighter-rouge">Q1</code> (abstract semantics). </p>

<h2 class="cc">3. The PreM property</h2>
  <p>If <code class="highlighter-rouge">T(R<sub>1</sub>, &hellip;, R<sub>k</sub>)</code> is a function defined by RA we say that a constraint <code class="highlighter-rouge">&gamma;</code>, is PreM to <code class="highlighter-rouge">T(R<sub>1</sub>, &hellip;, R<sub>k</sub>)</code> when the following property holds:
    <pre><code class="highlighter-rouge">&gamma;(T(R<sub>1</sub>, &hellip;, R<sub>k</sub>)) =  &gamma;(T(&gamma;(R<sub>1</sub>), &hellip;, &gamma;(R<sub>k</sub>)))</code></pre>
  </p>

  PreM for <strong>union</strong> has long been recognized and used as a cornerstone for parallel databases and <i>MapReduce</i>. Moreover the PreM property also holds
  for <strong>join</strong> and other operators, which provides a general solution to the semantic problem of having aggregates in recursive queries.</p>

  <p>Consider the RA expression <code class="highlighter-rouge">T</code> used in line 5 of Algorithm 2, which computes the new value of <code class="highlighter-rouge">wf'</code> from its old value <code class="highlighter-rouge">wf</code>.
  The PreM property holds for <code class="highlighter-rouge">max</code> if <code class="highlighter-rouge">max(T(wf)) = max(T(max(wf)))</code>, i.e. if the following relational expressions are equivalent:


  <pre><code class="language-sql">max(&#120587; (assbl(Spart,Part) &#8904; wf(Part,Days)))= max(&#120587; (assbl(Spart,Part) &#8904; max(wf(Part,Days))))</pre></code></p>


  <p>This PreM equality
   states  that the <code class="highlighter-rouge">max</code> waitfor days for a part is the <code class="highlighter-rouge">max</code>  of the max of days for each of its subparts.
   For simple queries such as this, proving the PreM property is  straightforward. Moreover, powerful techniques are available for proving that  complex expressions of RA and arithmetic operators are PreM w.r.t. extrema and other aggregates.</p>


  <p>With the PreM property holding, we can now observe that <code class="highlighter-rouge">max(wf(Part,Days))</code> simply denotes the application of max to the previous step in the computation of Algorithm 1, by applying the join and the PreM rule interchangeably, we can derive Algorithm 2 from Algorithm 1:
  </br>
  </br>
  <code class="highlighter-rouge">  max(wf<sub>n</sub>(Part,Days))</code> <br/>
  <code class="highlighter-rouge">= max(&#120587; (assbl(Spart,Part) &#8904; wf<sub>n-1</sub>(Part,Days)))</code> <br/>
  <code class="highlighter-rouge">= max(&#120587; (assbl(Spart,Part) &#8904; max(wf<sub>n-1</sub>(Part,Days)))</code> <br/>
  <code class="highlighter-rouge">= max(&#120587; (assbl(Spart,Part) &#8904; </code> <br/>
  <code class="highlighter-rouge">  max(&#120587; (assbl(Spart,Part) &#8904; max(wf<sub>n-2</sub>(Part,Days))))</code> <br/>
  <code class="highlighter-rouge">  &hellip; </code>  <br/>
  <code class="highlighter-rouge">= max(&#120587; (assbl(Spart,Part) &#8904; &hellip; </code>  <br/>
  <code class="highlighter-rouge">  max(&#120587; (assbl(Spart,Part) &#8904; max(basic))))</code></br>
  (Due to limited space, union is omitted, given that PreM holds for union) <br/>
  </p>

  <p>Symmetrically, if we start from Algorithm 2, we  see that <code class="highlighter-rouge">max(wf(Part,Days))</code>, i,e., the max applied to the previous step in the iteration, can be removed without changing the result.  Therefore, starting at line 2, and repeating this reasoning  for each successive step, we can remove each max from Algorithm 2 - except the one at the last step, that  will actually be applied at line 7. In  other words, we find that PreM allows us to transform Algorithm 1 into Algorithm 2 and vice-versa, thus providing a robust proof of the equivalence of  the operational semantics of Q1 and Q2.
  We also have that at the pure declarative level, the abstract semantics of Q1 and Q2 coincide, since the minimal fixpoint semantics for Q2 coincides with the perfect model of Q1.</p>

  <p>In addition to min and max, the PreM condition entails the use of count and sum in recursion.
  This is because, the count can be modeled as the max applied on the continuous monotonic count which can be freely used in recursion, and similar property hold for the sum of positive numbers. Thus for our BOM example, we can use a query similar to Q2 to efficiently compute the count of items used in an assembly, or to sum their costs. </p>

<p>Along with the improved aggregates in recursion semantics, we have an upgraded formal semantics since stable model semantics holds for transformed program in Q3.
<pre>
  <code class="language-sql">/*Q3: The PreM-optimized stable model of BOM query*/
  Relations: assbl(Part, Sub), basic(Part, Days).
  r<sub>1</sub>:ddays(Part, max&lt;Days&gt;) &#8592; basic(Part, Days).
  r<sub>2</sub>:ddays(Part, max&lt;Days&gt;) &#8592; assbl(Part, Sub), ddays(Sub, Days).
  query ddays(Part, MxDays).</code>
</pre>

<h2 class="cc">4. The Chain Aggregates</h2>
  <p> Along with the need for basic SQL aggregates in recursion, we identified the need for supporting chains of such aggregates which enable more compact and efficient expressions for various knowledge discovery algorithms. In chain aggregates, an invisible chain is introduced to chain upstream records with downstream ones according to specified constraints. In predictive analysis  this provides a general and  low-overhead way  to connect iterative tasks without compromising the original semantics of the queries.<br />

  <p> Let us now extend Q3 and assume that, along with the maximum time needed to obtain all the basic parts in an assembly, we want to discover which sub-part in each assembly is responsible for the longest waiting. By leveraging chain aggregates, the query can be modified into Q4, below, for such pursuit. <code class="highlighter-rouge">cmax</code> is leveraged in both <code class="highlighter-rouge">r<sub>1</sub></code> and <code class="highlighter-rouge">r<sub>2</sub></code> to find the maximum days at initial step, then recursively trace those sub-parts which lead to "maximum days" during the assembly procedure. In both rules, the attribute <code class="highlighter-rouge">Part</code> is implicitly defined as the group-by attribute for both <code class="highlighter-rouge">cmax</code> and <code class="highlighter-rouge">max</code>. Therefore, by executing this query, along with the maximum number of days required by the sub-parts of given a part to be delivered, the sub-part(s) causing this maximum  will also be returned.

<pre>
  <code class="language-sql">/*Q4: BOM query with Chain Aggregate: cmax*/
  Relations: assbl(Part, Sub), basic(Part, Days).
  r<sub>1</sub>:ddays(Part, max&lt;Days&gt;, cmax&lt;Part&gt;) &#8592; basic(Part, Days).
  r<sub>2</sub>:ddays(Part, max&lt;Days&gt;, cmax&lt;Sub&gt;) &#8592; assbl(Part, Sub), ddays(Sub, Days, _).
  query ddays(Part, Days, Sub).</code>
</pre>

<p>As shown in Q4, chain aggregates must be utilized in conjunction with <code class="highlighter-rouge">max</code> or <code class="highlighter-rouge">min</code> and the RaDlog compiler checks that <code class="highlighter-rouge">cmax</code> is bundled with <code class="highlighter-rouge">max</code> and <code class="highlighter-rouge">cmin</code> is bundled with <code class="highlighter-rouge">min</code>. The syntax of the chain aggregate <code class="highlighter-rouge">cmax</code> is shown in Definition below, and a dual definition  holds for <code class="highlighter-rouge">cmin</code>.
<pre>
  [Definition: Chain Max]<code class="highlighter-rouge"> In the head of a Datalog rule, the notation p(t<sub>1</sub>, &hellip; , t<sub>m-1</sub>, max< t<sub>m</sub> >, cmax< t<sub>m+1</sub>, &hellip; , t<sub>n</sub> >) 
  defines the n-argument predicate derived by computing max< t<sub>m</sub> > on the group-by attributes, t<sub>1</sub>, &hellip; , t<sub>m-1</sub>, 
  and applying cmax upon the arguments t<sub>m+1</sub>, &hellip; , t<sub>n</sub> correlated to max< t<sub>m</sub> >.
</code>
</pre>
<p> In above definition, <code class="highlighter-rouge">t<sub>m</sub></code> is called aggregate attribute and <code class="highlighter-rouge">t<sub>m+1</sub>, &hellip; , t<sub>n</sub></code> is regarded as chain attributes. Both chain and aggregate attributes are variables, and the <code class="highlighter-rouge">cmax</code> may take one or more variables (i.e., <code class="highlighter-rouge">m+1 < n</code>) as input, and generating <code class="highlighter-rouge">n</code> outputs. When multiple <code class="highlighter-rouge">(t<sub>m+1</sub>, &hellip; , t<sub>n</sub>)</code> instances share the same <code class="highlighter-rouge">max< t<sub>m</sub> ></code>, RaDlog supports two options: i) <code class="highlighter-rouge">cmax</code>, which returns all the instances of <code class="highlighter-rouge">(t<sub>m+1</sub>, &hellip; , t<sub>n</sub>)</code> , and ii) <code class="highlighter-rouge">scmax</code>, only single instance of <code class="highlighter-rouge">(t<sub>m+1</sub>, &hellip; , t<sub>n</sub>)</code> produced by the
max values will be returned. Dual properties hold for <code class="highlighter-rouge">cmin</code> and <code class="highlighter-rouge">scmin</code>.
  

</div>

<div id="example_body" class="container">
  <!-- <h1>RaSQL (Recursive-aggregate-SQL)</h1> -->
  <h2 id="examples">Knowledge Discovery Examples</h2>
  <p> We provide a list of data mining and machine learning example queries expressible in RaDlog. We first present the datalog query for implementing knowledge discovery models in RaDlog, then introduce the corresponding library(i.e. KDDLib) to help users build daily knowledge discovery tasks.

<h3 class="cc">1. Frequent Itemset</h3>
The original algorithm exploits the Apriori property that all nonempty subsets of a frequent itemset must also be frequent. We first describe the simple case where we only need to find those frequent itemsets with two items (i.e.M=2).
<pre>
  <code class="language-sql">Relations: trans(Tid: integer, Item: integer).
  r<sub>1</sub>:pair(Item1, Item2, count&lt;Tid&gt;) &#8592; trans(Tid, Item1), trans(Tid, Item2), Item1&lt;Item2.
  r<sub>2</sub>:fitset(M, Id, Item1) &#8592; pair(Item1, Item2, TCnt), TCnt&ge;{MS}, M=2, Id= (Item1 opc Item2).
  r<sub>3</sub>:fitset(M, Id, Item2) &#8592; pair(Item1, Item2, TCnt), TCnt&ge;{MS}, M=2, Id= (Item1 opc Item2).
  query fitset(M, Id, Item).</code>
</pre>
To address the case of M&ge;3, we continue with case M=2, and derive the following frequent itemsets Datalog query:

<pre>
  <code class="language-sql">Relations: trans(Tid: integer, Item: integer).
  r<sub>1</sub>:fitset(M, Id, Item) &#8592; init(M, Id, Item).
  r<sub>2</sub>:ovlp(M, Id1, Id2, count&lt;Item&gt;) &#8592; fitset(M, Id1, Item), fitset(M, Id2, Item), Id1&lt;Id2.
  r<sub>3</sub>:canset(M, Id1, Id2, Item) &#8592; ovlp(M, Id1, Id2, ItCnt), ItCnt=M-1, fitset(M, Id1, Item).
  r<sub>4</sub>:canset(M, Id1, Id2, Item) &#8592; ovlp(M, Id1, Id2, ItCnt), ItCnt=M-1, fitset(M, Id2, Item).
  r<sub>5</sub>:cantrans(M, Id1, Id2, Tid, count&lt;Item&gt;) &#8592; canset(M, Id1, Id2, Item), trans(Tid, Item).
  r<sub>6</sub>:canfreq(M, Id1, Id2, count&lt;Tid&gt;) &#8592; cantrans(M, Id1, Id2, Tid, ItCnt), ItCnt=M+1.
  r<sub>7</sub>:fitset(M1, Id, Item) &#8592; canset(M, Id1, Id2, Item), canfreq(M, Id1, Id2, TidCnt), TidCnt&ge;{MS}, Id=(Id1~opc~Id2), M1=M+1.

  query fitset(M, Id, Item).</code>
</pre>

<p> Leverage FrequentItemset() in the library to retrieve frequent itemsets.
<pre><code class="language-sql">  ...
  val fis = new FrequentItemset()
  fis.initlizeConfig()
  fis.setMinSupport(10)
  val trans = "testdata/fi/trans.csv"
  val freqItemset = fis.run(trans)
  ...
</code></pre>

<p> To leverage our proposed KDDLib for frequent pattern mining, users can first use <i>initialzeConfig()</i> to set default configurations, or utilize given functions to modify the configurations. With provided path of training data, the computation of frequent itemset is wrapped into <i>run()</i> function.

<h3 class="cc">2. Lloyd Clustering</h3>
<p> Among the many methods proposed, <i>K-means</i> (a.k.a. Lloyd clustering), still represents one
of the best known and widely used algorithm, and thus provides a natural candidate for a Datalog implementation.
In <i>K-means</i>, the default measure of closeness/similarity is the Euclidean distance. In particular, the <i>K-means</i> algorithm in data mining starts with a first group of randomly selected centroids, which are used as the beginning points for every cluster, and then performs iterative (repetitive) calculations to optimize the positions of the centroids. A centroid is the imaginary or real location representing the center of the cluster. The above example takes default configuration and generate trained clustering model as results. We first describe the datalog query for such pursuit:
<pre>
  <code class="language-sql">Relations: point(Pno: integer, Dim: integer, Val: double), init(Cno: integer, Dim: integer, Val: double).
  r<sub>1</sub>:center(0, Cno, Dim, Val) &#8592; init(Cno, Dim, Val).
  r<sub>2</sub>:dist(J, Pno, Cno, sum&lt;SqDis&gt;) &#8592; point(Pno, Dim, Val),center(J, Cno, Dim, CVal), SqDis=(Val-CVal)*(Val-CVal).
  r<sub>3</sub>:mdist(J, Pno, min&lt;DSum&gt;, scmin&lt;Cno&gt;) &#8592; dist(J, Pno, Cno, DSum)..
  r<sub>4</sub>:center(J1, Cno, Dim, avg&lt;Val&gt;) &#8592; point(Pno, Dim, Val), mdist(J, Pno, MDSum, Cno),J&lt;{TH}, J1=J+1.

  query center(J, Cno, Dim, Val).</code>
</pre>
We continue to show how to leverage LloydClustering() in the library to find centroids for each cluster.
<pre><code class="language-sql">  ...
  val lc = new LloydClustering()
  lc.initlizeConfig()
  ls.setNumClusters(4)
  val initPath = "testdata/cluster/init.csv"
  val pointPath = "testdata/cluster/point.csv"
  val model = lc.train(initPath, pointPath)
  ...
</code></pre>

<h3 class="cc">3. Decision Tree</h3>
<p> Classification is a form of supervised learning on how to best
categorize data into classes and concepts. Among the many classification techniques available, decision trees 
represent the most significant and popular method. Our proposed algorithm adopts a greedy (i.e., non-backtracking) approach in which decision trees are built in a top-down recursive divide-and-conquer manner. Thus, the training set is recursively partitioned into smaller subsets based on attribute selection measures (e.g. Gini Index). In above example, we utilize default configuration to construct a decision tree with given training datasets. We first describe the datalog query for building decision tree:

<pre>
  <code class="language-sql">Relations: train(Tid: integer, Col: integer, Val: integer), dec(Tid: integer, Dec: integer), set(Col: integer, Val: integer), col(Col: integer), init(Cid: integer, Sz: integer, Col: integer, Val: integer).
  r<sub>1</sub>:pattern(Cid,Sz,Col,Val) &#8592; init(Cid,Sz,Col,Val).
  r<sub>2</sub>:ext(Cid,Sz,Ncol,count&lt;Col&gt;) &#8592; col(Ncol), pattern(Cid,Sz,Col,Val),Col&lt;&gt;Ncol.
  r<sub>3</sub>:npat(Cid,Sz,Ncol,Nval,Col,Val) &#8592; ext(Cid,Sz,Ncol,CCnt), pattern(Cid,Sz,Col,Val), set(Ncol, Nval),Sz=CCnt.
  r<sub>4</sub>:npat(Cid,Sz, Ncol,Nval,Ncol,Nval) &#8592; ext(Cid,Sz,Ncol,CCnt),set(Ncol, Nval),Sz=CCnt.
  r<sub>5</sub>:candidate(Tid,Cid,Sz,Ncol,count&lt;Val&gt;) &#8592; npat(Cid,Sz,Ncol,Nval,Col,Val), train(Tid,Col,Val).
  r<sub>6</sub>:countdec(Cid,Sz,Ncol,Nval,Dec,count&lt;Tid&gt;) &#8592; candidate(Tid, Cid, Sz, Ncol, Cv),train(Tid, Ncol, Nval), dec(Tid, Dec), Cv=1.
  r<sub>7</sub>:gini(Cid, Sz, Ncol, Nval, Gini, Tc) &#8592; countdec(Cid, Sz, Ncol, Nval, Decy, Cy), Decy=1,countdec(Cid, Sz, Ncol, Nval, Decn, Cn),Decn=0,Tc = Cy + Cn, Gini= Tc- Cy*Cy/ Tc - Cn*Cn/Tc.
  r<sub>8</sub>:totalcol(Cid, Sz, Ncol, sum&lt;Tc&gt;) &#8592; gini(Cid, Sz, Ncol, Nval, Gini, Tc).
  r<sub>9</sub>:weightgini(Cid, Sz, Ncol, sum&lt;Gi&gt;) &#8592; gini(Cid, Sz, Ncol, Nval, Gini, Tc),totalcol(Cid, Sz, Ncol, Tot), Gi = Gini/Tot.
  r<sub>10</sub>:select(Cid, Sz, min&lt;WGi&gt;, scmin&lt;Ncol&gt;) &#8592; weightgini(Cid, Sz, Ncol, WGi).
  r<sub>11</sub>:pattern(Cidx, S1, Col, Val) &#8592; select(Cid, Sz, MGi, Ncol), Sz<{MD},S1=Sz+1,npat(Cid, Sz, Ncol, Nval, Col, Val),Cidx = ((Cid opc Ncol) opc Nval), MGi&gt;{TH}.

  query pattern(Cid,Sz,Col,Val).</code>
</pre>
We continue to show how to leverage DecisionTree() in the library to a decision tree with training datasets.
<pre><code class="language-sql">  
  /*Leverage DecisionTree() in the library*/
  val dtree = new DecisionTree()
  dtree.initlizeConfig()
  dtree.setImpurity("Gini")
  val initPath = "testdata/dt/pattern.csv"
  val setPath = "testdata/dt/set.csv"
  val trainPath = "testdata/dt/train.csv"
  val decPath = "testdata/dt/dec.csv"
  val colPath = "testdata/dt/col.csv"
  val model = dtree.trainClassifier(initPath, isetPath, trainPath, decPath, expandPath)
  ...
</code></pre>


  <h2 id="examples">RaSQL Examples</h2>
  <p>We provide a list of example queries expressible with RaSQL: Example 1-3 are classical graph queries; Example 4-8 demonstrate the power of aggregates in recursion to a broad range of application scenarios.</p>

  <h3 class="cc">1. Single-Source-Shortest-Path (SSSP):</h3>
  <p>
  <pre><code class="language-sql">/*Base tables:*/
edge(Src: int, Dst: int, Cost: double)

WITH recursive sp (Dst, min() AS Cost) AS
  (SELECT 1, 0)
   UNION
  (SELECT edge.Dst, sp.Cost + edge.Cost FROM sp, edge
   WHERE sp.Dst = edge.Src)
SELECT Dst, Cost FROM sp
</code></pre>

  The <strong>Single-Source-Shortest-Path (sssp)</strong> query finds paths with minimal costs from a given source node to all other nodes in the graph. The base relation <code class="highlighter-rouge">edge(Src, Dst, Cost)</code> describes all weighted directed edges in the graph. In this example, the sp relation is initialized with the source node 1. The cost to other nodes are iteratively computed by joining the existing weighted paths with the base relation edge, and the <code class="highlighter-rouge">min</code> aggregation is used to find the minimal path. </p>


  <h3 class="cc">2. Connected-Components (CC):</h3>
  <p>
  <pre><code class="language-sql">/*Base tables:*/
edge(Src: int, Dst: int)

WITH recursive cc (Src, min() AS CmpId) AS
  (SELECT Src, Src FROM edge)
   UNION
  (SELECT edge.Dst, cc.CmpId FROM cc, edge
	WHERE cc.Src = edge.Src)
SELECT count(distinct cc.CmpId) FROM cc
</code></pre>

  The idea of the <strong>Connected-Components</strong> query is label propagation: In the base case, each node is initially assigned its own <code class="highlighter-rouge">id</code> as the <code class="highlighter-rouge">CmpId</code>; In the recursive case, each node is receiving <code class="highlighter-rouge">CmpId</code> propagated from its neighbors in each iteration. The <code class="highlighter-rouge">min</code> aggregation restricts the <code class="highlighter-rouge">CmpId</code> of a node to be the minimal id received. The final result is calculated by counting the distinct number of <code class="highlighter-rouge">CmpId</code>s as all nodes within a single connected component will have the same (minimal) <code class="highlighter-rouge">CmpId</code> when the fixpoint is reached. </p>


  <h3 class="cc">3. Count Paths:</h3>
  <p>
  <pre><code class="language-sql">/*Base tables:*/
edge(Src: int, Dst: int)

WITH recursive cpaths (Dst, sum() AS Cnt) AS
  (SELECT 1, 1)
   UNION
  (SELECT edge.Dst, cpaths.Cnt FROM cpaths, edge
   WHERE cpaths.Dst = edge.Src)
SELECT Dst, Cnt FROM cpaths
</code></pre>

  The <strong>Count Paths</strong> query computes number of paths from a node to all nodes in a graph. Given the start node, the base case initializes the count to itself as 1. In the recursive case, the number of paths from the start node to another node is iteratively computed by adding up the path count from the start node to an intermediate node, which directly connects to the destination code.</p>


  <h3 class="cc">4. Delivery (BOM):</h3>
  <p>
  <pre><code class="language-sql">/*Base tables:*/
basic(Part: int, Days: int)
assbl(Part: int, Sub: int)

WITH recursive actualdays (Part, max() AS Mdays) AS
  (SELECT basic.Part, basic.Days FROM basic)
   UNION
  (SELECT assbl.Part, actualdays.Mdays
   FROM assbl, actualdays
   WHERE assbl.Sub = actualdays.Part)
SELECT Part, Mdays FROM actualdays
</code></pre>

  The <strong>delivery</strong> query computes the number of days until delivery for items in the application of BOM (Bill of materials). An item is either a basic item or needs to be assembled from other items. The basic item is represented by the base relation <code class="highlighter-rouge">basic(Part, Days)</code>, and the assembling relationship between items is represented by <code class="highlighter-rouge">assbl(Part, Sub)</code>.

  The basic item is delivered in pre-given days and the assembled item is delivered as soon as all its sub components are delivered (assuming assembling does not take extra days). In the base case, it computes the delivery days for all basic items. In the recursive case, it derives the delivery days for each item that needs assembling by finding the maximum delivery days among all its sub components. </p>


  <h3 class="cc">5. Management:</h3>
  <p>
  <pre><code class="language-sql">/*Base tables:*/
report(Emp: int, Mgr: int)

WITH recursive empCount (Mgr, count() AS Cnt) AS
  (SELECT report.Emp, 1 FROM report)
   UNION
  (SELECT report.Mgr, empCount.Cnt
   FROM empCount, report
   WHERE empCount.Mgr = report.Emp)
SELECT Mgr, Cnt FROM empCount
</code></pre>

  The <strong>management</strong> query calculates the total number of employees that a manager directly/indirectly manages in a large corporation. The base relation <code class="highlighter-rouge">report(Emp, Mgr)</code> describes the relationship between an employee and his/her manager. In the base case, the employee count for everyone is initialized to 1 (him/herself).
  In the recursive case, the employee count of a manager is iteratively computed by adding up the employee count of his/her direct reporters.</p>


  <h3 class="cc">6. MLM Bonus:</h3>
  <p>
  <pre><code class="language-sql">/*Base tables:*/
sales(M: int, P: double)
sponsor(M1: int, M2: int)

WITH recursive bonus(M, sum() as B) AS
  (SELECT M, P*0.1 FROM sales)
   UNION
  (SELECT sponsor.M1, bonus.B*0.5 FROM bonus, sponsor
   WHERE bonus.M = sponsor.M2)
SELECT M, B FROM bonus
</code></pre>

  Some companies adopt a multi-level marketing model to sell products, i.e. salesmen in such a company form a pyramid hierarchy: new members are recruited into the company by old members (sponsors), and get products from their sponsors. To incentive its members to recruit more people to sell more products, the company rewards each member by the bonus. The bonus is not only based on his/her own personal sales, but also the sales of each member in the network that he/she directly/indirectly sponsored.

  The query calculates the bonus that such a company needs to distribute to its members. The <code class="highlighter-rouge">sales</code> relation describes the gross profit <code class="highlighter-rouge">P</code> that each member makes, and the <code class="highlighter-rouge">sponsor</code> relation denotes the sponsor relationship. In the base case, it calculates the bonus that a member earns through the products that sold by himself/herself . In the recursive case, it calculate the bonus that derived from the sales of each member that he/she directly/indirectly sponsors.</p>


  <h3 class="cc">7. Interval Coalesce:</h3>
  <p>
  <pre><code class="language-sql">/*Base tables:*/
inter(S: int, E: int)

CREATE VIEW lstart(T) AS
  (SELECT a.S FROM inter a, inter b
   WHERE a.S &le; b.E
   GROUP BY a.S HAVING a.S = min(b.S))

WITH recursive coal (S, max() AS E) AS
  (SELECT lstart.T, inter.E FROM lstart, inter
   WHERE lstart.T = inter.S)
   UNION
  (SELECT coal.S, inter.E FROM coal, inter
   WHERE coal.S &le; inter.S AND inter.S &le; coal.E)
SELECT S, E FROM coal
</code></pre>

  The <strong>Interval Coalesce</strong> query finds the smallest set of intervals that cover input intervals. It is one of the most frequently used queries in temporal databases. However, it is notoriously difficult to write correctly in SQL.
  Here, we express it succinctly using RaSQL with the help of <code class="highlighter-rouge">max</code> aggregate.

  In the first part, a non-recursive view called <code class="highlighter-rouge">lstart</code> is created to find all left start points of intervals that are not covered by other intervals (except itself), using <strong>self-join</strong> of the base relation <code class="highlighter-rouge">inter(S, E)</code>. In the second part, the recursive view <code class="highlighter-rouge">coal(S, E)</code>, which represents the final coalesced intervals,
  is computed by iteratively extending the end points of intervals having the left starting points in <code class="highlighter-rouge">lstart</code> through merging other intervals which cover these end points.</p>


  <h3 class="cc">8. Party Attendance:</h3>
  <p>
  <pre><code class="language-sql">/*Base tables:*/
organizer(OrgName: str)
friend(Pname: str, Fname: str)

WITH recursive attend(Person) AS
  (SELECT OrgName FROM organizer)
   UNION
  (SELECT Name, Ncount FROM cntfriends
   WHERE Ncount >= 3),
recursive cntfriends(Name, count() AS Ncount) AS
  (SELECT friend.FName, friend.Pname
   FROM attend, friend
   WHERE attend.Person=friend.Pname)
SELECT Person FROM attend
</code></pre>

  More complex queries can be expressed in the <strong>mutual recursion</strong> fashion - the definition of a recursive relation includes references to other recursive relations.
  In this example, we want to know people who will attend the party - a person will attend the party if and only if three or more of his/her friends attend, or he/she is the organizer. The <code class="highlighter-rouge">attend</code> relation records people who will attend the party. The <code class="highlighter-rouge">cntfriends</code> relation records the number of a person's friends who will attend the party.
  These two relations are mutual recursive to each other and uses the results produced from the other in each recursive iteration. </p>


  <h3 class="cc">9. Company Control:</h3>
  <p>
  <pre><code class="language-sql">/*Base tables:*/
shares(By: str, Of: str, Percent: int)

WITH recursive cshares(ByCom, OfCom, sum() AS Tot) AS
  (SELECT By, Of, Percent FROM cshares)
   UNION
  (SELECT control.Com1, cshares.OfCom, cshares.Tot
   FROM control, cshares.ByCom
   WHERE control.Com2 = cshares.ByCom),
recursive control(Com1, Com2) AS
  (SELECT ByCom, OfCom, Percent
   FROM cshares
   WHERE Percent > 50)
SELECT ByCom, OfCom, Tot FROM cshares
</code></pre>

  The <strong>Company Control</strong> query was proposed by Mumick, Pirahesh and Ramakrishnan to calculate the complex controlling relationships between companies.
  Companies can purchase shares of other companies. In addition to the shares that a company owns directly, a company A owns shares that are controlled by a company B when A has a majority (over 50% of the total number) of B's shares. A tuple <code class="highlighter-rouge">(A, B, 51)</code> in the base relation <code class="highlighter-rouge">shares</code> indicates company <code class="highlighter-rouge">A</code> directly owns 51% of the shares of company <code class="highlighter-rouge">B</code>.
  This query also uses the <strong>mutual recursion</strong>: the <code class="highlighter-rouge">cshares</code> view recursively computes the percentage of shares that one company owns of another company while the <code class="highlighter-rouge">control</code> view decides whether one company controls another company.</p>

</div>

<div id="pub_body" class="container">
  <!-- <h1>RaSQL Publications</h1> -->
  <br />
  <ul>
    <li>Youfu Li, Jin Wang, Mingda Li, Ariyam Das, Jiaqi Gu, Carlo Zaniolo. <a href="" target="_blank">KDDLog: Performance and Scalability in Knowledge Discovery by Declarative Queries with Aggregates</a>, in submission for publication.</li>
  </ul>
  <!--ul>
    <li>Jin Wang, Jiacheng Wu, Mingda Li, Jiaqi Gu, Ariyam Das, Carlo Zaniolo. <a href="" target="_blank">Formal Semantics and High Performance in Declarative Machine Learning using Datalog</a>, in submission for publication.</li>
  </ul-->
  <ul>
    <li>Zaniolo, Carlo, Ariyam Das, Youfu Li, Mingda Li, and Jin Wang. <a href="" target="_blank">Formal semantics and scalability for datalog with aggregates: a cardinality-based solution</a>, ICLP, 2020</li>
  </ul>
  <ul>
    <li>Zaniolo, Carlo, Ariyam Das, Jiaqi Gu, Youfu Li, Mingda Li and Jin Wang. <a href="https://arxiv.org/pdf/1910.08888" target="_blank"> Monotonic properties of completed aggregates in recursive queries</a>, arXiv, 2019</li>
  </ul>
  <ul>
    <li>Jiaqi Gu, Yugo H. Watanabe, William A. Mazza, Alexander Shkapsky, Mohan Yang, Ling Ding, Carlo Zaniolo. <a href="http://yellowstone.cs.ucla.edu/papers/rasql.pdf" target="_blank">RaSQL: Greater Power and Performance for Big Data Analytics with Recursive-aggregate-SQL on Spark</a>, SIGMOD 19. <a href="https://dl.acm.org/citation.cfm?id=3299869.3324959" target="_blank"><span class="glyphicon glyphicon-file"></span>ACM DL</a></li>
  </ul>
  <ul>
    <li>Carlo Zaniolo, Mohan Yang, Matteo Interlandi, Ariyam Das, Alexander Shkapsky, Tyson Condie. <a href="https://pdfs.semanticscholar.org/61ff/5f2459ff2ce9004c02e9fd875145cf052110.pdf" target="_blank">Declarative BigData Algorithms via Aggregates and Relational Database Dependencies</a>, AMW 18.</li>
  </ul>
  <ul>
    <li>Carlo Zaniolo, Mohan Yang, Ariyam Das, Alexander Shkapsky, Tyson Condie, Matteo Interlandi. <a href="https://www.cambridge.org/core/journals/theory-and-practice-of-logic-programming/article/fixpoint-semantics-and-optimization-of-recursive-datalog-programs-with-aggregates/605FE14CADEA2567C9EDBB78BBD1E0A2" target="_blank">Fixpoint semantics and optimization of recursive Datalog programs with aggregates</a>, TPLP 17. <a href="https://arxiv.org/abs/1707.05681" target="_blank"><span class="glyphicon glyphicon-file"></span>arXiv</a></li>
  </ul>
  <ul>
    <li>Shkapsky, Alexander and Yang, Mohan and Interlandi, Matteo and Chiu, Hsuan and Condie, Tyson and Zaniolo, Carlo. <a href="https://dl.acm.org/doi/pdf/10.1145/2882903.2915229?casa_token=iOYDWGB7pNEAAAAA:qeoD00d-prcKPsMW13Y8K2ZKKSfpVxIvHSwiTYYJGmfHZUgVNtgV5ufnOpmB48GdlYhvlPWXWcYgyw" target="_blank">Big data analytics with datalog queries on spark</a>, SIGMOD, 2016.</li>
  </ul>
</div>

<div id="tutorial_body" class="container">
<p> RaDlog is a system supporting the execution of recursive query. It is built on top of Spark (branch 2.0) that includes the compiler and the distributed execution engine for the RaSQL (Recursive-aggregate-SQL) language and the traditional Datalog. It supersedes the BigDatalog system that previously developed at UCLA.

<p>The source code of RaDlog is available in Github (<a href="https://github.com/radlog-web/radlog">https://github.com/radlog-web/radlog</a>). Users who are interested in RaDlog can follow this tutorial to intall RaDlog and configure the environment in your machine.
<h3 class="cc">1. Build RaDlog</h3>
Download the source code from Github.
<pre>
  <code class="language-sql">$ git clone https://github.com/radlog-web/radlog.git</code>
</pre>
<br/>
RaDlog is built on Apache Spark using <a href="http://maven.apache.org/">Apache Maven</a>. To build RaDlog and its example programs, please make sure you are using JDK 1.8 or higher in your environment. Then you can run:
<pre>
  <code class="language-sql">$ cd /PATH-TO-RADLOG/radlog
  $ build/mvn -DskipTests clean package
  </code>
</pre>
<br/>
(You do not need to do this if you downloaded a pre-built package.)
<br/>
Similar to Spark, RaDlog can also be built using SBT, run:
<pre>
  <code class="language-sql">$ build/sbt compile</code>
</pre>
SBT is typically faster than Maven in development build. To build packaged jars, run:
<pre>
  <code class="language-sql">$ build/sbt package</code>
</pre>

Since RaDlog is built on top of Apache Spark, it follows the same building process of Spark. You can build Spark using more than one thread by using the -T option with Maven, see <a href="https://cwiki.apache.org/confluence/display/MAVEN/Parallel+builds+in+Maven+3">"Parallel builds in Maven 3"</a>. More detailed documentation is available from the project site, at <a href="http://spark.apache.org/docs/latest/building-spark.html">"Building Spark"</a>. For developing Spark using an IDE, see <a href="https://cwiki.apache.org/confluence/display/SPARK/Useful+Developer+Tools#UsefulDeveloperTools-Eclipse">Eclipse</a> and <a href="https://cwiki.apache.org/confluence/display/SPARK/Useful+Developer+Tools#UsefulDeveloperTools-IntelliJ">IntelliJ</a>.

<h3 class="cc">2. Run RaDlog Examples</h3>
An intuitive way to try RaDlog is shown as follows:
<pre>
  <code class="language-sql">$./bin/spark-submit --class edu.ucla.cs.wis.bigdatalog.spark.library.kddlog.LloydClustering --master local[2] ./datalog/target/scala-2.11/spark-datalog_2.11-2.0.3-SNAPSHOT.jar</code>
</pre>
<br/>

<h3 class="cc">3. RaDlog Configuration</h3>
Users can use the following parameters to configure your RaDlog environment
<table class="center">
  <tr>
    <th>Property Name</th>
    <th>Default</th>
    <th>Meaning</th>
  </tr>
  <tr>
    <td>spark.sql.sessionState</td>
    <td>radlog</td>
    <td>Choose between RaDlog and vanilla Spark mode. (radlog/spark)</td>
  </tr>
  <tr>
    <td>spark.sql.codegen.wholeStage</td>
    <td>false</td>
    <td>Enable whole Stage code generation.</td>
  </tr>
  <tr>
    <td>spark.sql.shuffle.partitions</td>
    <td>1</td>
    <td>The number of partitions to use when shuffling data for joins or aggregations. <b>Set it to cores-per-node * pinRDDHostLimit to enable the maximum parallelism</b>.</td>
  </tr>
  <tr>
    <td>spark.locality.wait </td>
    <td>0s</td>
    <td>How long to wait to launch a data-local task. Note in RaDlog's pinRDD mode, it should be set to 0 as we have Partition-Aware Scheduling.</td>
  </tr>
  <tr>
    <td>spark.datalog.pinRDDHostLimit</td>
    <td>0</td>
    <td><b>Any value greater than 0 will enable the pinRDD mode in distributed deployment.</b> In pinRDD mode, each RDD split will be pinned to a specific worker node during the recursive evaluation. This number determines how many workers will be used in pinRDD mode. TODO: remove the hard-coded Hosts file!!!</td>
  </tr>
    <tr>
    <td>spark.datalog.aggrIterType</td>
    <td>tungsten</td>
    <td>The aggregate iterator type.</td>
  </tr>
    <tr>
    <td>spark.datalog.packedBroadcast</td>
    <td>false</td>
    <td>Enable the packed Broadcast mode.</td>
  </tr>
    <tr>
    <td>spark.datalog.recursion.fixpointTask</td>
    <td>true</td>
    <td>Enable the decomposed execution when possible.</td>
  </tr>
    <tr>
    <td>spark.datalog.recursion.maxIterations</td>
    <td>Int.MaxValue</td>
    <td>Maximum iterations allowed before reaching the fixpoint.</td>
  </tr>
    <tr>
    <td>spark.datalog.recursion.nonMonotonic</td>
    <td>false</td>
    <td>Enable the non-Monotonic computation.</td>
  </tr>
</table>

<h3 class="cc">4. Spark Configuration</h3>
Please refer to the <a href="http://spark.apache.org/docs/latest/configuration.html">Configuration Guide</a> in the online documentation for an overview on how to configure Spark.

<h3 class="cc">5. A Note About Hadoop Versions</h3>
Spark uses the Hadoop core library to talk to HDFS and other Hadoop-supported storage systems. Because the protocols have changed in different versions of Hadoop, you must build Spark against the same version that your cluster runs.

Please refer to the build documentation at <a href="http://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version">"Specifying the Hadoop Version"</a> for detailed guidance on building for a particular distribution of Hadoop, including building for particular Hive and Hive Thriftserver distributions.

<h3 class="cc">6. Development with IntelliJ Idea</h3>
To develop RaDlog, we are using the IntelliJ Idea platform. Similar to building on your local machine, you need to build RaDlod using Maven or SBT and then package all compiled files into jar packages in IntelliJ Idea. For each program in RaDlog, the datalog file with the rules is put in a directory(./query). We are wrapping those queries into library. Users can also add their own library by following the same discipline described in radlog/datalog/src/main/scala/edu/ucla/cs/wis/bigdatalog/spark/library.
</div>

<div id="footer">
  <div class="container">
    <p class="text-muted credit">
      RaDlog Team at <a href="http://wis.cs.ucla.edu/wis/">University of California, Los Angeles</a>, <abbr title="last build date April 22 2019">2020</abbr>
      <!--a href="https://github.com/rasql-web" class="pull-right">Edit this page</a-->
    </p>
  </div>
</div>

<script src="prism.js"></script>
<script async="" src="//www.google-analytics.com/analytics.js"></script><script src="https://code.jquery.com/jquery-2.1.0.min.js"></script>
<script src="//netdna.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js"></script>
<script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-52534109-1', 'auto');
  ga('send', 'pageview');
</script>

<script type="text/javascript">
  function hide_all() {
    document.getElementById('intro_body').style.display = 'none';
    document.getElementById('lang_body').style.display = 'none';
    document.getElementById('example_body').style.display = 'none';
    document.getElementById('pub_body').style.display = 'none';
    document.getElementById('tutorial_body').style.display = 'none';
  }

  function show(id) {
    hide_all();
    document.getElementById(id).style.display = 'block';
  }

  hide_all();
  show('intro_body');
</script>

</body>

</html>
